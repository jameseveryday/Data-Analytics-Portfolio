{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "maakGmIuKa8Q",
        "45PJd-Tb26Uv",
        "FBxWNX4nGZEJ",
        "SDKekccL2NHR",
        "qOwWY8MSNDi3",
        "fzoaiYEGS0_t",
        "h5ZeEA4gws0C",
        "k9J7rKfZxFFb",
        "il0fS8EGiDAa",
        "_Pdg1aV6sx50",
        "DUneDojFKZ0q",
        "Ik0k8j-Jl_yJ",
        "_rNeHLjzm8fd"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jameseveryday/james-portfolio/blob/main/hotel_booking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyzing Hotel Booking Cancellations\n",
        "## Module 5 Python Final Task"
      ],
      "metadata": {
        "id": "NDHFF-V21ihu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Welcome to the Module 5 Final Task in Python. For this notebook, we will be applying all the concepts that we have previously learned in order to solve a business-related problem.\n",
        "\n",
        "In order to finish the task, we will have to supply the necessary python codes in order to achieve the expected output. Some of the tasks given contain hints and guides to achieve the expected output"
      ],
      "metadata": {
        "id": "rHzVMWox2b7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Guides on Answering the task\n",
        "\n",
        "For this Final Task, there are cells needed to be run, edited, or filled-out, and it would be categorized in three (3) categories:\n",
        "\n",
        "1. Cells that only needs to run: These types of cells **don't need changes or additions to the code** and you would **just have to run them**. If this cell returns an error, the problem would be on the previous cell(s) that come before it.\n",
        "```python\n",
        "# Run the given cell\n",
        "variable = function(arg1,arg2)\n",
        "```\n",
        "\n",
        "2. Cells that are fill-in-the-blanks: These types of cells are commented and would have to edit the cell by uncommenting the code and fill in the missing parts in order to achieve a particular objective.\n",
        "```python\n",
        "# Fill in the blanks\n",
        "# ________ = __._______(________)\n",
        "```\n",
        "When filled-out, this would turn into:\n",
        "```python\n",
        "# Fill in the blanks\n",
        "variable = pd.function('value')\n",
        "```\n",
        "\n",
        "3. Cells that are completely blank: These cells do need to provide the code from scratch to achieve a particular objective.\n",
        "```python\n",
        "# Enter your code here\n",
        "```\n",
        "```python\n",
        "# Enter your code here\n",
        "my_data.method(arg='value', arg2='value2')\n",
        "```"
      ],
      "metadata": {
        "id": "maakGmIuKa8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although, there would be times that a \"Hint\" option would be given alongside the given objective. We can click them to show a hint in order to achieve a particular task."
      ],
      "metadata": {
        "id": "Xh9s4eVQNVQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Press \"Hint\" below to show a hint.**\n",
        "\n",
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "You will be able to see a hint inside this area, something to keep in mind.\n",
        "\n",
        "```python\n",
        "# Some example codes would be given here as well\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "Ml8RYWG1G2aa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Business Context\n",
        "\n",
        "As a Data Analyst of a company owning a city hotel in a metropolitan area and a resort hotel located near a coastline both within the United States, you've been assigned by your manager to provide insights on the recent rise of hotel booking cancellations in both hotels for the past few months. These events causes the management to suffer financial losses and they would like to know some leads on reasons why customers cancel their room reservations."
      ],
      "metadata": {
        "id": "4AOYM2Qp3nmF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "You've been given a dataset containing a list of bookings recorded in the booking system. Each row consist a booking made for a particular date and it also contains details containing the following:\n",
        "\n",
        "| Column Name                    | Description                                                                 |\n",
        "|--------------------------------|-----------------------------------------------------------------------------|\n",
        "| hotel                          | The type of hotel the booking was made                                      |\n",
        "| lead_time                      | The time (in hours) between the booking date and the expected arrival date  |\n",
        "| arrival_date_year              | The year of guest's expected arrival                                        |\n",
        "| arrival_date_month             | The month of guest's expected arrival                                       |\n",
        "| arrival_date_day_of_month      | The day of the month of guests's expected arrival                           |\n",
        "| adults                         | Describes how many guests in the booking are adults                         |\n",
        "| children                       | Describes how many guests in the booking are children                       |\n",
        "| babies                         | Describes how many guests in the booking are babies                         |\n",
        "| meal                           | A category that describes what type of meal ordered by the guest |\n",
        "| country                        | Country of Origin (in ISO 3166 Alpha-3 code format)                         |\n",
        "| is_repeated_guest              | Describes whether or not the guest have booked before                       |\n",
        "| previous_cancellations         | Describes the number of previous cancellations by the guest                 |\n",
        "| previous_bookings_not_canceled | Describes the number of previous non-canceled bookings by the guest         |\n",
        "| reserved_room_type             | A category that describes what room type the guest reserved                 |\n",
        "| assigned_room_type             | A category that describes what room type the guest received                 |\n",
        "| booking_changes                | The number of changes the customer did on the booking                       |\n",
        "| deposit_type                   | The type of payment deposit used by the guest                               |\n",
        "| days_in_waiting_list           | Describes the number of days the guest was in the waiting list              |\n",
        "| customer_type                  | Describes the type of guest in the booking                                  |\n",
        "| adr                            | The potential \"Average Daily Revenue\" of the booking                        |\n",
        "| car_parking_spaces             | The number of car parking spaces requested by the guest                     |\n",
        "| special_requests               | The number of special requests given by the guest                           |\n",
        "| status                         | The updated status of the booking                                           |\n",
        "| status_last_update             | The date of the status registered to the booking system                     |"
      ],
      "metadata": {
        "id": "uJzBxe7r4tjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Python Libraries\n",
        "\n",
        "For us to analyze the given data, we first have to import the necessary Python libraries."
      ],
      "metadata": {
        "id": "45PJd-Tb26Uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1: Import the following python libraries to be used for this task\n",
        "\n",
        "- `pandas` with alias `pd`\n",
        "- `matplotlib.pyplot` with alias `plt`\n",
        "- `seaborn` with alias `sns`"
      ],
      "metadata": {
        "id": "FBxWNX4nGZEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your code here\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "RuYFhW8K3m6T"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Loading\n",
        "\n",
        "Now that we've imported the libaries, it's time to load up the dataset.\n",
        "\n",
        "For this task, we're going to load up the `.csv` file named `hotel_bookings_data.csv`."
      ],
      "metadata": {
        "id": "SDKekccL2NHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2: Load the `.csv` file into a pandas dataframe and store it in a variable named `data`.\n",
        "\n",
        "Note: For us to find the dataset stored in our drive, you may want to first mount the drive by clicking on the mount button, or by running the given code below"
      ],
      "metadata": {
        "id": "Sfzm_FbxIf06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5dTZ2IYfIQ73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another thing is that we make sure to download the given dataset and upload it to your Drive. You may use the given link for download:\n",
        "```\n",
        "https://drive.google.com/uc?export=download&id=1sd_kQmPppftKdSIeSL2MXXc7bwQoveTr\n",
        "```"
      ],
      "metadata": {
        "id": "K4EC9vnPNl70"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After mounting the drive and uploading the dataset on it, we can import the given dataset."
      ],
      "metadata": {
        "id": "nyejReARJ08e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWPm56ydvjYh"
      },
      "outputs": [],
      "source": [
        "# Fill in the blanks\n",
        "\n",
        "# data = ____._______(__________)\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Refocus/Module 5. Lesson 10. Final Task/hotel_bookings_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "You can use pandas `read_csv()` function in order to load up a `.csv` file.\n",
        "```python\n",
        "my_variable = pd.read_csv('file/to/path.csv', ...)\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "VJdBdzZSKH3U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check if the loading was successful, we can use the `.head()` method to show the top 5 rows in the data"
      ],
      "metadata": {
        "id": "C5lHdIhyLm2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "data.head()"
      ],
      "metadata": {
        "id": "6olzBC9mLlvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also check the dataframe details as well using `.info()` method"
      ],
      "metadata": {
        "id": "107KVL5QMRQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "data.info()"
      ],
      "metadata": {
        "id": "-TDk4BsIMaFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning\n",
        "\n",
        "Before proceeding to the analysis, we would have to clean up the data first.\n",
        "\n",
        "Keep in mind that before analyzing any form of data, we have to make sure that the data we have on hand is clean and free of irregularities."
      ],
      "metadata": {
        "id": "AsQHN9Hi2PIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3: Remove all completely duplicated rows in the dataframe `data`\n",
        "\n"
      ],
      "metadata": {
        "id": "qOwWY8MSNDi3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To start off, we can first check if there are any duplicates found in the dataset.\n"
      ],
      "metadata": {
        "id": "hs_ytDksPNyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "data[data.duplicated()]"
      ],
      "metadata": {
        "id": "XP5xLdy5Ou0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We found that there are around 32 thousand rows that are considered as complete duplicates. We have to first remove them in our `data` dataframe\n",
        "\n",
        "Provide the code where the expected output is that our dataframe `data` no longer have duplicate values"
      ],
      "metadata": {
        "id": "i7UBgEODPQb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your code here\n",
        "data = data.drop_duplicates()\n",
        "data"
      ],
      "metadata": {
        "id": "5p5Xp7Ax2Z56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "There are many possible ways to remove the shown duplicates.\n",
        "\n",
        "You can use the `drop_duplicates()` method to remove the complete duplicates in the given dataframe e.g. `my_dataframe.drop_duplicates()`\n",
        "\n",
        "Another method is to get the indexes of the duplicates, and filter out using `~`\n",
        "```python\n",
        "index_duplicates = my_dataframe.duplicated().index\n",
        "```\n",
        "```python\n",
        "my_dataframe[~index_duplicates]\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "fpaMg8tFP4Lc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check, we can verify that there would only be 87300 rows left in our dataframe `data`. Running the `assert` cell should not return an error.\n",
        "\n",
        "If there was an error, we have to check whether we correctly remove the duplicates in the data."
      ],
      "metadata": {
        "id": "48uXGsf-Rw2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "KbuQBmFnR8JQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "\n",
        "assert(data.shape == (87300, 24))"
      ],
      "metadata": {
        "id": "rDfiVLpGSBiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4: Check the Columns containing Missing Values"
      ],
      "metadata": {
        "id": "fzoaiYEGS0_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we finished on cleaning the duplicates, it's time to clean-up the missing values in our dataset.\n",
        "\n",
        "For us to check which columns have missing values, we have to create a pandas series named `num_missing_cols` that shows a list of columns along with the number of missing values indicated as `NaN`, and sort based on their values in descending order."
      ],
      "metadata": {
        "id": "5TtYuj1LT8H1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the blanks\n",
        "\n",
        "# ____________ = data.____().____().______(ascending=______)\n",
        "num_missing_cols = data.isna().sum().sort_values(ascending=False)\n",
        "num_missing_cols"
      ],
      "metadata": {
        "id": "V-AsJMCDS5bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "We can use `.isna()` to tell whether a given data is `NaN` or not, then use `.sum()` to sum these number of `NaN` by column, and use `.sort_values()` to sort their counts.\n",
        "\n",
        "We can implement the idea using method chaining.\n",
        "\n",
        "Example:\n",
        "```python\n",
        "my_dataframe.method_1().method_2().method_3(argument='value')\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "dWer5l-26bun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "\n",
        "print(num_missing_cols)"
      ],
      "metadata": {
        "id": "Q3Vf5gtnup8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For us to verify our progress, we would be running some `assert` statements and see if it results to an error.\n",
        "\n",
        "If it shows an error, it means that we have to modify our code to the correct one."
      ],
      "metadata": {
        "id": "RscrWu5ouMX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "\n",
        "assert(type(num_missing_cols) == pd.Series)\n",
        "assert(num_missing_cols.shape == (24,))\n",
        "assert(all(num_missing_cols[:3] == [451,4,0]))"
      ],
      "metadata": {
        "id": "NtJr5Wr5ukXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see in our counts that both columns `country` and `children` have missing values. We would be cleaning them in the next task."
      ],
      "metadata": {
        "id": "flUqiDiV9hqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 5: Clean the `country` and `children` column by providing a default value\n",
        "\n",
        "When we look at the `country` and `children` columns further:"
      ],
      "metadata": {
        "id": "h5ZeEA4gws0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "\n",
        "data[data['country'].isna()].head()"
      ],
      "metadata": {
        "id": "kF3uFaIfyOsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "\n",
        "data[data['children'].isna()].head()"
      ],
      "metadata": {
        "id": "siuflgcY89LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there are some rows have missing values indicated as `NaN`.\n",
        "\n",
        "There are several methods in order for our data to be cleaned. One of the methods is called \"imputation\" which is providing the best guess of what data can be applied to the missing values.\n",
        "\n",
        "In the `country` column, there might be some guests that do not have a particular country of origin, or if the guest has a particular country of countries to choose from when applying for a hotel booking.\n",
        "\n",
        "<br>\n",
        "\n",
        "**With that kind of scenario, it would be best to keep these rows and provide a value labeled `Other` to the missing values in the `country` column.**"
      ],
      "metadata": {
        "id": "jTOIcYS49T3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "data['country'] = data['country'].fillna('Other')"
      ],
      "metadata": {
        "id": "pHnC-03Ex4WY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "We can use `.fillna()` in order to fill out the missing values in the column:\n",
        "\n",
        "Examples:\n",
        "```python\n",
        "my_dataframe['col_name'] = my_dataframe['col_name'].fillna('default value')\n",
        "```\n",
        "\n",
        "```python\n",
        "my_dataframe['col_name'].fillna('default value', inplace=True)\n",
        "```\n",
        "\n",
        "Both of these examples would yield the same result. It's only in the matter of preference.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "-FwYuOaI_wEG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the other hand, there are missing values in the `children` column. There are a variety of reasons why there are missing values in this column. In this case, you've learned from the company's previous analysis that it's most likely the guests have no children but forgot to fill the data in the column.\n",
        "\n",
        "<br>\n",
        "\n",
        "**In this case, we can impute the missing data by filling out with `0` on the `children` column.**"
      ],
      "metadata": {
        "id": "1rOtE4TU-5VH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "data['children'] = data['children'].fillna(0)"
      ],
      "metadata": {
        "id": "2A4XYS91-4_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "Same as the previous one, we can still use `.fillna()` in order to fill out the missing values in the column:\n",
        "\n",
        "Examples:\n",
        "```python\n",
        "my_dataframe['col_name'] = my_dataframe['col_name'].fillna('default value')\n",
        "```\n",
        "\n",
        "```python\n",
        "my_dataframe['col_name'].fillna('default value', inplace=True)\n",
        "```\n",
        "\n",
        "Both of these examples would yield the same result. It's only in the matter of preference.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "xZ1LRMD1AIac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For us to verify our progress, we'll going to initially check them using `assert` statement. If the following cell yields an error, we might have to check our code again to have the correct answer. Otherwise, our code would be correct"
      ],
      "metadata": {
        "id": "eOUOmleeAOd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "\n",
        "assert(all(data[['country','children']].isna().sum() == 0))"
      ],
      "metadata": {
        "id": "VqesR0rtyzgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 6: Clean the date-related columns by creating a column with datetime data type."
      ],
      "metadata": {
        "id": "k9J7rKfZxFFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, we would be cleaning up the date columns by converting them into a `datetime` data type.\n",
        "\n",
        "The process of cleaning up date columns may vary, and this is one way that you can use in order to clean up the date columns."
      ],
      "metadata": {
        "id": "nQvCIGEsBGpS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we observe our arrival date at hand:"
      ],
      "metadata": {
        "id": "viwqeEVgB2_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "\n",
        "cols_to_use = ['arrival_date_year','arrival_date_month','arrival_date_day_of_month', 'status_last_update']\n",
        "\n",
        "data[cols_to_use].head()"
      ],
      "metadata": {
        "id": "t0JEi72WB3Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "\n",
        "data[cols_to_use].info()"
      ],
      "metadata": {
        "id": "wwB8DHzYCF1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that are three columns that defines the arrival date of a particular guest. On the other hand, we have `status_last_update` which contains all the date data in a column.\n",
        "\n",
        "Our objective here is to first convert these columns arrival date columns to a string, and concatenate them. Afterwards, convert this concatenated column along with `status_last_update` to a `datetime` data type."
      ],
      "metadata": {
        "id": "nZHKSoABCI8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First, convert the year and the day columns indicated as `arrival_date_year` and `arrival_date_day_of_month` respectively to a string column `str`.**"
      ],
      "metadata": {
        "id": "rxsgII_L143H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "data[['arrival_date_year', 'arrival_date_day_of_month']] = data[['arrival_date_year', 'arrival_date_day_of_month']].astype('str')"
      ],
      "metadata": {
        "id": "x8VDc_OO1z2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "We can use `.astype('type')` in order to fill out the missing values in the column. Alternatively, we can use a `lambda` function to convert them as well.\n",
        "\n",
        "Examples:\n",
        "```python\n",
        "my_dataframe['col_name'] = my_dataframe['col_name'].astype('int')\n",
        "```\n",
        "\n",
        "```python\n",
        "my_dataframe['col_name'] = my_dataframe['col_name'].apply(lambda x: int(x))\n",
        "```\n",
        "\n",
        "Both of these examples would yield the same result. It's only in the matter of preference.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "v-_sisAfC7iQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**After converting them to `str`, we merge the three columns into a single column named `arrival_date` following the format `YYYY-Month-DD`**\n",
        "\n",
        "Examples: `2015-July-1`, `2017-August-30`"
      ],
      "metadata": {
        "id": "WNNKgR8c2eqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the blanks\n",
        "\n",
        "# col_arrival_dates = ['arrival_date_year','arrival_date_month','arrival_date_day_of_month']\n",
        "# data['arrival_date'] = data[_______].____(lambda x: '_____'._____(x), axis=1)\n",
        "\n",
        "col_arrival_dates = ['arrival_date_year','arrival_date_month','arrival_date_day_of_month']\n",
        "data['arrival_date'] = data[col_arrival_dates].apply(lambda x: '-'.join(x), axis=1)"
      ],
      "metadata": {
        "id": "uHgdA4jpzUWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "Inside `.apply()`, we can use a `lambda` function where it uses a string operator `.join()` to merge the three columns.\n",
        "\n",
        "Example:\n",
        "```python\n",
        "ex_cols = ['year_col', 'month_col','day_col']\n",
        "\n",
        "my_dataframe['col_name'] = my_dataframe[ex_cols].apply(lambda x: '/'.join(x), axis=1)\n",
        "```\n",
        "```python\n",
        "my_dataframe['col_name'].head()\n",
        "```\n",
        "```\n",
        "1972/04/23\n",
        "2020/01/17\n",
        "1998/09/30\n",
        "1989/12/9\n",
        "2000/02/6\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "8K3W4_ZbEQKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To show our results:"
      ],
      "metadata": {
        "id": "Aq9e3xDJKBoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "\n",
        "print(data['arrival_date'])"
      ],
      "metadata": {
        "id": "uaXJPZszIceu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For us to check our progress, we would be running some `assert` statements and see if it results to an error.\n",
        "\n",
        "If it shows an error, it means that we have to modify our code to the correct one."
      ],
      "metadata": {
        "id": "uLH8XCYGHQ6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "\n",
        "assert(pd.api.types.is_string_dtype(data['arrival_date']))\n",
        "assert(all(data['arrival_date'].apply(lambda x: x.count('-')) == 2))\n",
        "assert(data['arrival_date'].isna().sum() == 0)\n",
        "assert(data['arrival_date'].shape == (87300,))"
      ],
      "metadata": {
        "id": "A9hHmshbGUx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next, convert the `arrival_date` and `status_last_update` column into a datetime data type using `pd.to_datetime`**"
      ],
      "metadata": {
        "id": "klRKSrxz391W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[['arrival_date', 'status_last_update']].head(3)"
      ],
      "metadata": {
        "id": "lfw1MqGp74ES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "data['arrival_date'] = pd.to_datetime(data['arrival_date'])\n",
        "data['status_last_update'] = pd.to_datetime(data['status_last_update'])"
      ],
      "metadata": {
        "id": "1hBDVWjI2h0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "We can use `pd.to_datetime()` like in the given example:\n",
        "```python\n",
        "my_dataframe['col_name'] = pd.to_datetime(my_dataframe['col_name'])\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "4XCn_h3yJbhu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finally, remove the columns listed in `col_arrival_dates` in the dataframe `data`.**"
      ],
      "metadata": {
        "id": "Myvx_V8W_OEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "data = data.drop(col_arrival_dates, axis=1)"
      ],
      "metadata": {
        "id": "lCola6fv-6h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "We can use `.drop()` method to remove the columns like in the given examples:\n",
        "```python\n",
        "col_list = ['col1', 'col2', 'col3']\n",
        "my_dataframe = my_dataframe.drop(col_list, axis=1)\n",
        "```\n",
        "```python\n",
        "col_list = ['col1', 'col2', 'col3']\n",
        "my_dataframe.drop(col_list, axis=1, inplace=True)\n",
        "```\n",
        "\n",
        "Both codes yield the same results. It's only in the matter of preference.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "fUYyPY3LSYYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check our data cleaning process, we would be running some `assert` cells. If the cell below produces an error, we would have to check our codes above and revise it accordingly."
      ],
      "metadata": {
        "id": "8DF19GivUrq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert(data.shape == (87300, 22))\n",
        "assert(pd.api.types.is_datetime64_dtype(data['arrival_date']))\n",
        "assert(pd.api.types.is_datetime64_dtype(data['status_last_update']))"
      ],
      "metadata": {
        "id": "EelmUjkuU4Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 7: Checking for Outliers\n",
        "\n",
        "To avoid producing skewed results, we would be checking on the validity of our data inputs by removing outliers in the data.\n",
        "\n",
        "Outliers can take up different forms and meanings depending on the type of data at hand, but the common thing about them is that these are the data that are \"almost impossible\" to happen in the real world and these data can affect our results and summary statistics when left unnoticed."
      ],
      "metadata": {
        "id": "il0fS8EGiDAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Show the summary statistics of the column `adr` in the dataframe `data`, and store the results into a variable `adr_summary`.**"
      ],
      "metadata": {
        "id": "Ftcjb7Pbnbg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "adr_summary = data['adr'].describe()\n",
        "adr_summary"
      ],
      "metadata": {
        "id": "hpWtFhsZnYcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "We can use `.describe()` method to show the summary statistics of a column:\n",
        "```python\n",
        "my_dataframe['col_name'].describe()\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "BpN8pjDj1JIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "\n",
        "print(adr_summary)"
      ],
      "metadata": {
        "id": "uVvRSZ_bogqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll check if we got it correctly using `assert`"
      ],
      "metadata": {
        "id": "cWgszUAbp2M0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "\n",
        "assert(all(adr_summary.index == pd.Index(['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'])))\n",
        "assert(adr_summary.shape == (8,))"
      ],
      "metadata": {
        "id": "G2rs1dhqpHo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the numbers, this wouldn't depict the outliers properly. What we can do here is to show a plot instead."
      ],
      "metadata": {
        "id": "r3Rv_1CFobP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Show a plot describing the histogram of `adr` in the data. Set the y-axis scale to `log` and give it a title named \"Histogram of Hotel Guest ADR\"**"
      ],
      "metadata": {
        "id": "kgqRQbsNnhwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the blanks\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(10,6))\n",
        "# ax = data['______'].plot(kind='_______', bins=30)\n",
        "\n",
        "# ax.set_title('Histogram of Hotel Guest ADR')\n",
        "# ax.set_yscale('log')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "ax = data['adr'].plot(kind='hist', bins=30)\n",
        "\n",
        "ax.set_title('Histogram of Hotel Guest ADR')\n",
        "ax.set_yscale('log')\n",
        "\n",
        "# adr = Average Daily Revenue"
      ],
      "metadata": {
        "id": "28uoBNoWh2Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking into our results, we can see that there's a lone data point in the 5000 range, and it wouldn't make sense to have an `adr` that high, so we check on the raw data by sorting the values in `adr`\n",
        "\n"
      ],
      "metadata": {
        "id": "_W8GkUFl0Q94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "\n",
        "data['adr'].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "ISLoNqHA0mzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that there's one data that is very high compared to the rest. Another thing is that our lowest value is a negative number, so we remove it as well in our dataset.\n",
        "\n",
        "Remove the rows that contains an `adr` of `5400` and `-6.38`"
      ],
      "metadata": {
        "id": "qVMKlI0I0tYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "condition_filter = (data['adr'] != 5400) & (data['adr'] != -6.38)\n",
        "data = data[condition_filter]\n",
        "data"
      ],
      "metadata": {
        "id": "uXXXgE_f0sD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "There are many ways that we can do in order to remove the data in our dataframe.\n",
        "\n",
        "We can use a condition filter like this:\n",
        "```python\n",
        "condition_filter = my_dataframe['col'] != 0\n",
        "my_dataframe = my_dataframe[condition_filter]\n",
        "```\n",
        "\n",
        "We can get the index of the row and remove it using `.drop()`:\n",
        "```python\n",
        "index_row = 123\n",
        "my_dataframe = my_dataframe.drop(index_row)\n",
        "```\n",
        "\n",
        "We can use `.isin()` method and negate the result using `~`.\n",
        "```python\n",
        "my_dataframe = my_dataframe[~my_dataframe['col'].isin([0])]\n",
        "```\n",
        "\n",
        "All of these methods would yield the same output. It's only on the matter of preference\n",
        "\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "Z-Bkimb58tVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "\n",
        "data['adr'].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "GtLg33MO15gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify our progress, we would be running some `assert` statements. If it yields an error, kindly revise our previous code and try again."
      ],
      "metadata": {
        "id": "uexCxU8R3n5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "\n",
        "assert(data[data['adr'].isin([5400, -6.38])].shape == (0,22))\n",
        "assert(data['adr'].min() == 0)\n",
        "assert(data['adr'].max() == 510)"
      ],
      "metadata": {
        "id": "4vjzdQBa2cLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Analysis and Insights"
      ],
      "metadata": {
        "id": "-u37L-y_2QQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have cleaned our data, it's time to start on our Data Analysis for this task. Keep in mind the business objective is to learn why guests cancel their hotel room reservations.\n",
        "\n",
        "For us to explore further, we can show the context of our data through Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "sD4hhYxYf7IL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 8: Show the amount lost from cancelled bookings\n",
        "\n",
        "To find out how much did the company loss from cancelled hotel bookings, we would look into the data by showing some summary statistics and a bar plot."
      ],
      "metadata": {
        "id": "_Pdg1aV6sx50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First, create a subset dataframe named `amount_plotdata` that excludes the rows where `status` is `No-Show`.**"
      ],
      "metadata": {
        "id": "0Fck1Yvq2w1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "amount_plotdata = data[data['status'] == 'No-Show']\n",
        "amount_plotdata"
      ],
      "metadata": {
        "id": "PJYOyieCvO9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "We can create a condition to filter out data in the dataframe like in this example:\n",
        "```python\n",
        "my_dataframe = my_dataframe[my_dataframe['col1'] != 'value']\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "_7B5UMVX2_MT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, create a seaborn barplot that uses the data `amount_plotdata`, `x` with `'status'`, `y` with `'adr'`, and `hue` with `'deposit_type'`.\n",
        "\n",
        "Label the chart title `Average Daily Rate of Hotel Bookings`, the x label with `Booking Status`, y label with `Average Daily Rate`, and the legend title with `Deposit Type`."
      ],
      "metadata": {
        "id": "kGcsE2xf3QAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the blanks\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(10,5))\n",
        "# sns.barplot(data=__________, x='_______', y='_______',\n",
        "#             hue='_______',ax=ax)\n",
        "\n",
        "# ax.set_title('__________')\n",
        "# ax.set_xlabel('__________')\n",
        "# ax.set_ylabel('__________')\n",
        "# ax.legend(title='__________')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "sns.barplot(data=amount_plotdata, x='status', y='adr',\n",
        "            hue='deposit_type',ax=ax)\n",
        "\n",
        "ax.set_title('Average Daily Rate of Hotel Bookings')\n",
        "ax.set_xlabel('Booking Status')\n",
        "ax.set_ylabel('Average Daily Rate')\n",
        "ax.legend(title='Deposit Type')"
      ],
      "metadata": {
        "id": "MLBz28GEvz6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, we would show the summary statistics using the column `adr` grouped by `status` and `deposit_type`."
      ],
      "metadata": {
        "id": "qH3JrTIJ3xb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the blanks\n",
        "\n",
        "# amount_plotdata.groupby(['________','________'])['________'].describe()\n",
        "\n",
        "amount_plotdata.groupby(['status','deposit_type'])['adr'].describe()"
      ],
      "metadata": {
        "id": "5fVCPA84wuIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 9: Use `.groupby()` method to tally the cancellations and compute the cancellation rates per day"
      ],
      "metadata": {
        "id": "DUneDojFKZ0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For us to look into the cancellations further, we can plot them over time. But first, we have to supply the appropriate data before we can plot them."
      ],
      "metadata": {
        "id": "ghlh7sl84heD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create three new columns named `arrival_day`, `arrival_month`, and `arrival_year` that uses `arrival_date` which gets the day, month, and year respectively.**"
      ],
      "metadata": {
        "id": "02dLFUlJ4uYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the blanks\n",
        "\n",
        "# data['_________'] = data['_________'].__.__\n",
        "# data['_________'] = data['_________'].__.__\n",
        "# data['_________'] = data['_________'].__.__\n",
        "\n",
        "data['arrival_day'] = data['arrival_date'].dt.day\n",
        "data['arrival_month'] = data['arrival_date'].dt.month\n",
        "data['arrival_year'] = data['arrival_date'].dt.year"
      ],
      "metadata": {
        "id": "4FXBnGenM7-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "You can use the `.dt.year`, `.dt.month`, and `.dt.day` attribute of a series\n",
        "\n",
        "Example:\n",
        "```python\n",
        "my_dataframe['date_col'].dt.year\n",
        "my_dataframe['date_col'].dt.month\n",
        "my_dataframe['date_col'].dt.day\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "iCSjYW8z45wJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next, we create a new column named `is_canceled` that contains boolean values whether the column `status` has the value `Canceled` or not.**"
      ],
      "metadata": {
        "id": "ffC4pib35UDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['status'].value_counts()"
      ],
      "metadata": {
        "id": "DDKnrBtEQRlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the blanks\n",
        "\n",
        "# data['_________'] = (data['_________'] == '_________')\n",
        "\n",
        "data['is_canceled'] = (data['status'] == 'Canceled')\n",
        "data['is_canceled'].value_counts()"
      ],
      "metadata": {
        "id": "ZvN1oI7ONc6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We then use `.groupby()` method to group the given arrival columns and find the `sum` and `count` of cancelled bookings and store the results to a variable named `canceled_data`**"
      ],
      "metadata": {
        "id": "EdPysaRx5h-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the blanks\n",
        "\n",
        "# grouping_cols = ['arrival_year','arrival_month','arrival_day']\n",
        "# canceled_data = data._______(grouping_cols)['is_canceled'].agg(['____','___']).reset_index()\n",
        "\n",
        "grouping_cols = ['arrival_year','arrival_month','arrival_day']\n",
        "canceled_data = data.groupby(grouping_cols)['is_canceled'].agg(['sum','count']).reset_index()\n",
        "canceled_data"
      ],
      "metadata": {
        "id": "yws0mu5MM1Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then create a new column named `cancel_rate` that is computed by dividing the columns `sum` and `count` from the dataframe `canceled_data`\n",
        "\n",
        "```\n",
        "cancel_rate = column_of_sum / column_of_count\n",
        "```"
      ],
      "metadata": {
        "id": "iQGyE1nk5upM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "canceled_data['cancel_rate'] = canceled_data['sum'] / canceled_data['count']"
      ],
      "metadata": {
        "id": "TRikh0_ONav4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "We can add a column from a computed value in Python like this\n",
        "\n",
        "Example:\n",
        "```python\n",
        "my_dataframe['new_col'] = my_dataframe['col1'] + my_dataframe['col2']\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "PhIWvU-_6bVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "\n",
        "canceled_data.head()"
      ],
      "metadata": {
        "id": "2WJEMe-LOE49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 10: Show a line plot of hotel booking cancellation rate"
      ],
      "metadata": {
        "id": "Ik0k8j-Jl_yJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the created dataframe named `canceled_data`, create a lineplot using `sns.lineplot` containing the given arguments:\n",
        "- `data`: `canceled_data`\n",
        "- `x`: `'arrival_month'`\n",
        "- `y`: `'cancel_rate'`\n",
        "- `hue`: `'arrival_year'`\n",
        "- `style`: `'arrival_year'`\n",
        "- `markersize`: `10`\n",
        "- `palette`: `'Dark2'`\n",
        "- `ci`: `None`\n",
        "- `markers`: `True`\n",
        "- `dashes`: `False`\n",
        "- `ax`:`ax`\n",
        "\n",
        "Lastly, set the title named `Line Plot of Hotel Cancellation Rates Per Year`, x label named `Month Number`, y label named `Cancellation Rate`, the legend title named `Year`."
      ],
      "metadata": {
        "id": "ba3WB3rV7WQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the blanks\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(10,5))\n",
        "# sns.lineplot(data=_______, x='_______', y='_______',\n",
        "#              hue='_______', style='_______',\n",
        "#              markersize=__, palette='_______', ci=_______,\n",
        "#              markers=_______, dashes=_______,\n",
        "#              ax=__)\n",
        "\n",
        "# ax.set_xticks(range(1,13))\n",
        "\n",
        "# ax.set_title('____________________________________')\n",
        "# ax.set_xlabel('____________')\n",
        "# ax.set_ylabel('____________')\n",
        "\n",
        "# ax.legend(title='____')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "sns.lineplot(data=canceled_data, x='arrival_month', y='cancel_rate',\n",
        "             hue='arrival_year', style='arrival_year',\n",
        "             markersize=10, palette='Dark2', ci=None,\n",
        "             markers=True, dashes=False,\n",
        "             ax=ax)\n",
        "\n",
        "ax.set_xticks(range(1,13))\n",
        "\n",
        "ax.set_title('Line PLot of Hotel Cancellation Rates Per Year')\n",
        "ax.set_xlabel('Month Number')\n",
        "ax.set_ylabel('Cancellation Rate')\n",
        "\n",
        "ax.legend(title='Year')"
      ],
      "metadata": {
        "id": "l5cOetKfahRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 11: Use `.groupby()` method to tally the cancellations and compute the cancellation rates per deposit type and returning guest"
      ],
      "metadata": {
        "id": "_rNeHLjzm8fd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We then use `.groupby()` method to group the given columns and find the `sum` and `count` of cancelled bookings and store the results to a variable named `pointplot_data`**"
      ],
      "metadata": {
        "id": "3xk_-cw58jf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the blanks\n",
        "\n",
        "# grouping_cols = ['deposit_type','is_repeated_guest','arrival_date']\n",
        "# pointplot_data = data.groupby(grouping_cols)['is_canceled'].agg(['sum','count']).reset_index()\n",
        "\n",
        "grouping_cols = ['deposit_type','is_repeated_guest','arrival_date']\n",
        "pointplot_data = data.groupby(grouping_cols)['is_canceled'].agg(['sum','count']).reset_index()\n",
        "pointplot_data.head(3)"
      ],
      "metadata": {
        "id": "0aPYBW3wV5vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then create a new column named `cancel_rate` that is computed by dividing the columns `sum` and `count` from the dataframe `pointplot_data`\n",
        "\n",
        "```\n",
        "cancel_rate = column_of_sum / column_of_count\n",
        "```"
      ],
      "metadata": {
        "id": "GlMntyio8r_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "pointplot_data['cancel_rate'] = pointplot_data['sum'] / pointplot_data['count']\n",
        "pointplot_data.head(3)\n"
      ],
      "metadata": {
        "id": "WlQMbWBiZpHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "We can add a column from a computed value in Python like this\n",
        "\n",
        "Example:\n",
        "```python\n",
        "my_dataframe['new_col'] = my_dataframe['col1'] + my_dataframe['col2']\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "ld3BQpQW8yKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we convert the column of `is_repeated_guest` to a data type `bool`."
      ],
      "metadata": {
        "id": "B30tNqo28ziR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "pointplot_data['is_repeated_guest'] = pointplot_data['is_repeated_guest'].astype('bool')"
      ],
      "metadata": {
        "id": "xZs4w7e_qf7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "We can use `.astype('type')` in order to fill out the missing values in the column. Alternatively, we can use a `lambda` function to convert them as well.\n",
        "\n",
        "Examples:\n",
        "```python\n",
        "my_dataframe['col_name'] = my_dataframe['col_name'].astype('int')\n",
        "```\n",
        "\n",
        "```python\n",
        "my_dataframe['col_name'] = my_dataframe['col_name'].apply(lambda x: int(x))\n",
        "```\n",
        "\n",
        "Both of these examples would yield the same result. It's only in the matter of preference.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "knXmY6ZS9WXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given cell\n",
        "\n",
        "pointplot_data.head()"
      ],
      "metadata": {
        "id": "9EeNwMFy9bJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 12: Show a Pointplot of Cancellation Rates by Deposit Type"
      ],
      "metadata": {
        "id": "bVI55Dw1X8Rf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the created dataframe named `pointplot_data`, create a poinplot using `sns.lineplot` containing the given arguments:\n",
        "- `data`: `pointplot_data`\n",
        "- `x`: `'deposit_type'`\n",
        "- `y`: `'cancel_rate'`\n",
        "- `hue`: `'is_repeated_guest'`\n",
        "- `join`: `False`\n",
        "- `capsize`:`0.1`\n",
        "- `ax`:`ax`\n",
        "\n",
        "Lastly, set the title named `Cancellation Rates by Deposity type and Repeating Guest`, x label named `Deposit Type`, y label named `Cancellation Rate`, the legend title named `Returning Guest`."
      ],
      "metadata": {
        "id": "vqWIiHOC9iYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the blanks\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(7,8))\n",
        "# sns.pointplot(data=_______, x='_______', y='_______',\n",
        "#               hue='_______', join=_______,\n",
        "#               capsize=____, ax=___)\n",
        "\n",
        "# ax.set_xlabel('_______')\n",
        "# ax.set_ylabel('______________')\n",
        "# ax.set_title('____________________________')\n",
        "# ax.legend(title='____________________________')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7,8))\n",
        "sns.pointplot(data=pointplot_data, x='deposit_type', y='cancel_rate',\n",
        "              hue='is_repeated_guest', join=False,\n",
        "              capsize=0.1, ax=ax)\n",
        "\n",
        "ax.set_xlabel('Deposit Type')\n",
        "ax.set_ylabel('Cancellation Rate')\n",
        "ax.set_title('Cancellation Rates by Deposit Type and Repeating Guest')\n",
        "ax.legend(title='Returning Guest')"
      ],
      "metadata": {
        "id": "dI0tnO9rgLG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 13 (Optional): Other Analysis and Insights"
      ],
      "metadata": {
        "id": "QiVxh2HhyOmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This portion of the Final Task is not required to answer but it is highly recommended to do so.**\n",
        "\n",
        "For this part, this would be the place where you can provide additional plots, charts, visualizations, and insights that may be interesting into your report. Although, if you have no insights that you want to share, you can skip to the next part (\"Conclusions and Recommendations\").\n",
        "\n",
        "You may add code or text cells by pointing your mouse to the end of a code cell and click \"Code\" or \"Text\".\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "ohKRR8SVyR9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can delete your cell by pressing the delete icon on the top right of the cell:\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "4_HWwkJr1j6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some of the things that we can explore using the given data (You can choose as much as you can):\n",
        "- Relationship between cancellation rates and the number of special requests or booking changes\n",
        "- Frequency of Cancellations by Resort Type and the presence of children per guest\n",
        "- Relation between the number of days in the waiting list to guest's cancellation\n",
        "- Solo/Couple guest vs. Family guest cancellation rates\n",
        "- Influence of lead time to guest cancellation\n",
        "\n",
        "Correspondingly, you may these methods to support your insights as well (if applicable):\n",
        "- RFM analysis\n",
        "- Hypothesis Testing"
      ],
      "metadata": {
        "id": "Joi6AAffz7wn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, you may add text cells if you wanted to provide some written explanation of the analysis that we make here."
      ],
      "metadata": {
        "id": "Bh7oyOtt1ZKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You may freely add cells and write code for this part"
      ],
      "metadata": {
        "id": "9FYWNgmmJZWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "PcR0FLer49yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 1\n",
        "# Relationship between cancellation rates and the number of special requests or booking changes\n",
        "cancellation_sr_bc = data.groupby(['special_requests', 'booking_changes'])['is_canceled'].mean().unstack()\n",
        "cancellation_sr_bc\n",
        "\n",
        "# Creating heatmap\n",
        "plt.figure(figsize=(20, 3))\n",
        "sns.heatmap(cancellation_sr_bc, annot=True, cmap='mako_r')\n",
        "plt.title('Relationship between Cancellation Rates and Special Requests or Booking Changes')\n",
        "plt.xlabel('Booking Changes')\n",
        "plt.ylabel('Special Requests')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3fOI9IHeyRNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 2\n",
        "# Frequency of Cancellations by Resort Type and the presence of children per guest\n",
        "cancellation_frequency = data.groupby(['hotel', 'children'])['is_canceled'].mean().unstack()\n",
        "cancellation_frequency\n",
        "\n",
        "# Plotitng frequencies\n",
        "plt.figure(figsize=(7.5, 2.5))\n",
        "sns.heatmap(cancellation_frequency, annot=True, cmap='mako_r')\n",
        "plt.xlabel('Presence of Children')\n",
        "plt.ylabel('Resort Type')\n",
        "plt.title('Frequency of Cancellations by Resort Type and Presence of Children Per Guest')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mc79GBHUJFOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 3\n",
        "# Solo/Couple guest vs. Family guest cancellation rates\n",
        "data['guest_type'] = data.apply(lambda row: 'Solo/Couple'\n",
        "                                if row['adults'] <= 2\n",
        "                                else 'Family', axis=1)\n",
        "\n",
        "# Calculate cancellation rates for each guest type\n",
        "cancellation_guest_type = data.groupby('guest_type')['is_canceled'].mean()\n",
        "\n",
        "# Plot the cancellation rates\n",
        "plt.figure(figsize=(2.5, 2.5))\n",
        "sns.barplot(x=cancellation_guest_type.index, y=cancellation_guest_type.values)\n",
        "plt.xlabel('Guest Type')\n",
        "plt.ylabel('Cancellation Rate')\n",
        "plt.title('Cancellation Rates for Solo/Couple Guest vs. Family Guest')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LviAu4HXaGtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusions and Recommendations"
      ],
      "metadata": {
        "id": "FhXng66greVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this part, we would have to provide overall conclusion based on the observations and insights that we made in the previous part.\n",
        "\n",
        "You may write down at least 2 sentences on what can you can observe in the data in general and what you can recommend to the management in order to resolve the increased booking cancellations given the results and insights that you've made so far.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "PANUI_posK7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Write your answer by double-clicking on this sentence*\\\n",
        "-------------------------------------------------------------------------------\\\n",
        "**Conclusions** :\n",
        "\n",
        "Referring to Section 2 and 3, most of booking cancellations came from Guests who have at least 2 children. We can explore this area to recommend steps to minimize booking cancellations since it is affecting revenue. Also, there are numerous special requests and booking changes that maybe disrupting management resulting to more cancellations.\\\n",
        "-------------------------------------------------------------------------------\\\n",
        "**Recommendations**\n",
        "\n",
        "1.   Explore family-friendly amentities.\n",
        "        - Explore rooms, facilities, and amenities. Have a checklist to cater especially guests with children. This could include play areas, kiddie pools, kid-friendly menus, family-friendly suites, and offer engaging activities for families.\n",
        "2.   Market offers and packages for families with children.\n",
        "        - Offer packages such as discount rates, bundled packages, and etc for families with multiple children. This could include free meals/snacks, children entertainment, family-catered attractions, and etc.\n",
        "3.   Provide transparency on offers.\n",
        "        - Clear communication from hotel staff and management. Clear expectation from what is offered in the advertisments, room amenities, room configurations, policies to avoid misunderstanding. Seek feedback and reviews from guests to aim lowering booking changes and special requests.\n",
        "4.   Train staff to fulfill more of family needs especially with multiple children and addressing concerns promptly. Seek feedback and reviews from guests."
      ],
      "metadata": {
        "id": "vF5WnzyOzAg9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**END OF FILE**"
      ],
      "metadata": {
        "id": "9A7GXLBfzFmf"
      }
    }
  ]
}